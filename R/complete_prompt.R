#' Complete a Custom GPT-3 Prompt
#'
#' @param prompt The prompt to use as input for GPT-3
#' @param model  Which model variant of GPT-3 to use. Defaults to 'text-davinci-003'
#' @param openai_api_key Your API key. By default, looks for a system environment variable called "OPENAI_API_KEY" (recommended option). Otherwise, it will prompt you to enter the API key as an argument.
#' @param max_tokens How many tokens (roughly 4 characters of text) should GPT-3 return? Defaults to a single token (next word prediction).
#' @param temperature A number between 0 and 100. When set to zero, GPT-3 will always return the most probable next token. When set higher, GPT-3 will select the next word probabilistically.
#'
#' @return If max_tokens is 1, returns a dataframe with the 5 most likely next words and their probabilities as assigned by GPT-3. If max_tokens > 1, returns a single string of text generated by GPT-3.
#' @export
#'
#' @examples
#' complete_prompt('I feel like a')
#' complete_prompt('Write a haiku about frogs.', max_tokens = 100)
complete_prompt <- function(prompt,
                            model = 'text-davinci-003',
                            openai_api_key = Sys.getenv('OPENAI_API_KEY'),
                            max_tokens = 1,
                            temperature = 0) {


  openai <- reticulate::import("openai")

  if(is.null(openai_api_key) | Sys.getenv('OPENAI_API_KEY') == ''){
    stop("No API key detected in system environment. You can enter it manually using the 'openai_api_key' argument.")
  } else{
    openai$api_key = openai_api_key
  }

  # query the API
  response <- openai$Completion$create(
    engine = model,
    prompt = prompt,
    logprobs = ifelse(max_tokens == 1, as.integer(5), as.integer(1)),
    max_tokens = as.integer(max_tokens),
    temperature = as.integer(temperature)
  )

  # if user requests more than one token, returns a single autoregressively generated response from GPT-3
  if(max_tokens > 1){
    return(response$choices[[1]]$text)
  } else{
    # if user requests 1 token (default), return the vector of next word predictions
    # and their associated log probabilities

    # convert the dictionary of log probabilities into a dataframe
    keys <- names(response$choices[[1]]$logprobs$top_logprobs[[1]])

    logprobs <- numeric(length(keys))

    for(i in 1:length(keys)){
      logprobs[i] <- response$choices[[1]]$logprobs$top_logprobs[[1]]$get(keys[i])
    }

    data.frame(response = keys,
               prob = exp(logprobs))
  }

}
